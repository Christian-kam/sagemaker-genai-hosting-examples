{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d5ea8f-d271-48d9-b7fc-cca34355d92b",
   "metadata": {},
   "source": [
    "# Deploy the Gemma 3 4b instruct for inference using Amazon SageMakerAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb65300",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to deploy and use the Gemma 3 4B instruct model on Amazon SageMaker. Gemma is a family of lightweight, open-source language models developed by Google, designed to be efficient and easy to use. By following this guide, you'll learn how to set up the model, deploy it as an endpoint, and interact with it for both text and image-based tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43672fee-fb40-476d-b2e2-d487839e85ac",
   "metadata": {},
   "source": [
    "In this notebook, you will learn how to deploy the Gemma 3 4B instruct model (HuggingFace model ID: google/gemma-3-4b-it) using Amazon SageMaker AI. The inference image will be [HuggingFace TGI](https://github.com/huggingface/text-generation-inference/releases/tag/v3.2.0)(Text Generation Inference) on Amazon SageMaker [TGI 3.2.0](https://github.com/aws/deep-learning-containers/releases?q=tgi+AND+gpu&expanded=true)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4db9c-f915-4280-a027-430280ffacb5",
   "metadata": {},
   "source": [
    "[Gemma 3 models](https://ai.google.dev/gemma/docs/core) are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9831e992-c626-461e-b98c-e25e89a35df0",
   "metadata": {},
   "source": [
    "**License agreement**\n",
    "- This model is gated on HuggingFace, please refer to the original [model card](https://huggingface.co/google/gemma-3-4b-it) for license.\n",
    "- This notebook is a sample notebook and not intended for production use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2599542-ced5-41f4-a16b-eb9f442dcec2",
   "metadata": {},
   "source": [
    "### Install or upgrade SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7094d34c-c571-4e0c-8407-aa859f07d248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65041d7-7650-47d8-a109-898d20018bf8",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0f1377-139c-43c5-8e44-90b1bd8019e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "from sagemaker.session import Session\n",
    "import logging\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f347d1-7646-45ec-bb9f-640ed72a35ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma-3-4b-it'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_MODEL_ID = \"google/gemma-3-4b-it\"\n",
    "\n",
    "base_name = HF_MODEL_ID.split('/')[-1].replace('.', '-').lower()\n",
    "model_lineage = HF_MODEL_ID.split(\"/\")[0]\n",
    "base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa1dfe4-80c3-4456-90dc-afc909568c79",
   "metadata": {},
   "source": [
    "### Create SageMaker Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3669b27",
   "metadata": {},
   "source": [
    "Amazon SageMaker is a fully managed service that provides developers and data scientists the ability to build, train, and deploy machine learning (ML) models quickly. SageMaker removes the heavy lifting from each step of the ML process, making it easier to develop high-quality models. The SageMaker Python SDK provides open-source APIs and containers to train and deploy models on SageMaker, using several different ML and deep learning frameworks.\n",
    "\n",
    "[Hugging Face](https://huggingface.co/) is a popular open-source platform and company that specializes in natural language processing (NLP) and artificial intelligence. Amazon SageMaker AI lets customers train, fine-tune, and run inference using Hugging Face models for Natural Language Processing (NLP) on SageMaker AI. You can use Hugging Face for both training and inference. \n",
    "\n",
    "AWS and Hugging Face collaborate to simplify and accelerate adoption of Natural Language Processing models.\n",
    "\n",
    "For inference, customer can use your trained Hugging Face model or one of the pre-trained Hugging Face models to deploy an inference job with [SageMaker AI](https://docs.aws.amazon.com/sagemaker/latest/dg/hugging-face.html). With this collaboration, you only need one line of code to deploy both your trained models and pre-trained models with SageMaker AI. You can also run inference jobs without having to write any custom inference code. With custom inference code, you can customize the inference logic by providing your own Python script.\n",
    "\n",
    "\n",
    "Hosting large language models like Gemma on cloud platforms such as Amazon SageMaker offers several advantages:\n",
    "\n",
    "1. **Scalability**: Easily adjust resources based on demand.\n",
    "2. **Cost-efficiency**: Pay only for the compute resources you use.\n",
    "3. **Managed infrastructure**: AWS handles the underlying infrastructure, allowing you to focus on model deployment and usage.\n",
    "4. **Integration**: Seamlessly connect with other AWS services for comprehensive AI/ML pipelines.\n",
    "5. **Security**: Leverage AWS's robust security features to protect your model and data.\n",
    "\n",
    "By using SageMaker, we can deploy Gemma in a production-ready environment with minimal overhead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b71226-638f-4a4f-8037-825d5ca19bb5",
   "metadata": {},
   "source": [
    "#### Set up huggingface token\n",
    "Gemma-3-4B-Instruct is a gated model so you will need to provide your [Hugging face token](https://huggingface.co/docs/hub/en/security-tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15623090-662f-4317-9806-f88c50aa9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = 'hf_xxxxxxxxxx' #change to your own token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14152bb6-9c8f-4f0b-aa73-1f791ace9821",
   "metadata": {},
   "source": [
    "#### Set up model environment variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2f9deb-d217-4b5b-9338-799a0aeefa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = {\n",
    "    \"HF_MODEL_ID\": 'google/gemma-3-4b-it',\n",
    "    \"ENDPOINT_SERVER_TIMEOUT\": \"1200\",\n",
    "    \"SM_NUM_GPUS\": \"1\",\n",
    "    \"HUGGING_FACE_HUB_TOKEN\": hf_token,\n",
    "    \"PREFIX_CACHING\": \"0\",  \n",
    "    \"USE_PREFIX_CACHING\":\"0\", \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f026da7a-f230-49f7-9a89-204ca89437bd",
   "metadata": {},
   "source": [
    "#### Set image URI\n",
    "Currently need to hard code the [image URI](https://github.com/aws/deep-learning-containers/releases?q=tgi+AND+gpu&expanded=true) to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb45dbc2-4778-4403-a516-16f755deb8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgi_image_uri = '763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.6.0-tgi3.2.0-gpu-py311-cu124-ubuntu22.04-v2.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5d40ee-000b-4072-a46b-c67bad3f941f",
   "metadata": {},
   "source": [
    "#### Create HuggingFaceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c448f",
   "metadata": {},
   "source": [
    "HuggingFaceModel is a class provided by Amazon [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html) that simplifies the process of deploying models from the Hugging Face Hub on Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "226068aa-7de5-4270-afc2-9f0ca1f7f9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemma-3-4b-it2025-04-07-07-11-21'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = base_name + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3732b1ee-b459-46dd-b75d-42e4ffafa88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_tgi_model = HuggingFaceModel(\n",
    "    image_uri=tgi_image_uri,\n",
    "    env=hub,\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    sagemaker_session=session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c8797d-a098-426f-9e47-cf1ecf276666",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4275d3eb",
   "metadata": {},
   "source": [
    "Deploying the model creates a SageMaker endpoint - a fully managed HTTPS endpoint that can be used for real-time inference. We are using \"ml.g5.2xlarge\" instance type. This process may take several minutes as SageMaker provisions the necessary resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae37d7f-c939-4b94-9263-d621bbbc5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpointName = model_name+\"endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44036b5d-4802-47cb-af64-f44e2c544324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/07/25 07:13:28] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: gemma-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>-4b-it2025-04-07-07-11-21             <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/07/25 07:13:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: gemma-\u001b[1;36m3\u001b[0m-4b-it2025-04-07-07-11-21             \u001b]8;id=356452;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=958933;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         gemma-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>-4b-it2025-04-07-07-11-21endpoint                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=638654;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=241817;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         gemma-\u001b[1;36m3\u001b[0m-4b-it2025-04-07-07-11-21endpoint                               \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04/07/25 07:13:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name gemma-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>-4b-it2025-04-07-07-11-21endpoint   <a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04/07/25 07:13:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name gemma-\u001b[1;36m3\u001b[0m-4b-it2025-04-07-07-11-21endpoint   \u001b]8;id=703461;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=307923;file:///opt/conda/lib/python3.11/site-packages/sagemaker/session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_tgi_predictor = gemma_tgi_model.deploy(\n",
    "    endpoint_name= endpointName,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\", #1 gpu\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7df7c6b5-cc03-43b9-9433-129e38d162e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Deploy, Endpint status: InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "client = boto3.client('sagemaker')\n",
    "readyflag = False\n",
    "if not readyflag:\n",
    "    response = client.describe_endpoint(EndpointName=endpointName)\n",
    "    status = response['EndpointStatus']\n",
    "    if status != \"Creating\":\n",
    "        readyflag = True\n",
    "        print(\"Finished Deploy, Endpint status: \" + status)\n",
    "    else:\n",
    "        time.sleep(30)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ba526-a6e7-408b-b07a-934a9bbdab44",
   "metadata": {},
   "source": [
    "### Invocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909401b",
   "metadata": {},
   "source": [
    "Once the endpoint is deployed, we can send requests to it for inference. The Gemma model can handle both text-only and multimodal (text + image) inputs. \n",
    "\n",
    "**Model Input:**\n",
    "Text string, such as a question, a prompt, or a document to be summarized\n",
    "Images, normalized to 896 x 896 resolution and encoded to 256 tokens each\n",
    "Total input context of 128K tokens for the 4B, 12B, and 27B sizes, and 32K tokens for the 1B size\n",
    "\n",
    "**Model Output:**\n",
    "Generated text in response to the input, such as an answer to a question, analysis of image content, or a summary of a document\n",
    "Total output context of 8192 tokens\n",
    "\n",
    "We'll demonstrate both types of interactions in the following examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb03ee5-c4c3-47fb-ac21-4bde43880e68",
   "metadata": {},
   "source": [
    "#### Option 1 - Invoke use predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b215c4-27f1-49ae-a0bb-1e93c7069421",
   "metadata": {},
   "source": [
    "**Text as model Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e61bbec-05aa-49d3-b0a5-e9d1b2648d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"\\n\\nI'm an AI assistant created by Google. I can assist you with a variety of tasks, including:\\n\\n*   **Answering your questions:** I can provide information on a huge range of topics. Just ask!\\n*   **Generating creative text formats:** I can write stories, poems, code, scripts, musical pieces, email, letters, etc.\\n*   **Summarizing text:** I can condense long articles or documents into shorter summaries.\\n*   **Translating languages:** I can translate between many different languages.\\n*   **Brainstorming ideas:** I can help you come up with ideas for projects, stories, or anything else.\\n*   **Performing calculations:** I can do math problems.\\n*   **Following your instructions:** I can execute your commands and requests.\\n\\n**To help me assist you best, please be as specific as possible with your requests.**\\n\\nSo, what's on your mind? Do you have a question, need help with something, or just want to chat?\"}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_tgi_predictor.predict({\n",
    "\t\"inputs\": \"Hi, what can you help me with?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b79901d-1866-4ab0-86ad-8dc255c224f2",
   "metadata": {},
   "source": [
    "**Multimodality - Image as input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664afadb-5deb-45bb-8cbd-011c01d4c9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image as IPyImage\n",
    "IPyImage(url=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG\", height=300, width= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0cbb777-761d-4bd1-a95e-b9a6a47f820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the image, the animal on the candy is a **turtle**. You can clearly see the shell shape printed on the teal candy.\n",
      "=== Token Usage ===\n",
      "Prompt Tokens: 284\n",
      "Completion Tokens: 29\n",
      "Total Tokens: 313\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "payload = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"image_url\", \n",
    "          \"image_url\": {\"url\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG\"},\n",
    "        },\n",
    "        {\"type\": \"text\", \"text\": \"What animal is on the candy?\"}\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = pretrained_tgi_predictor.predict(payload)\n",
    "print(response['choices'][0]['message']['content'])\n",
    "\n",
    "# Print usage statistics\n",
    "print(\"=== Token Usage ===\")\n",
    "usage = response['usage']\n",
    "print(f\"Prompt Tokens: {usage['prompt_tokens']}\")\n",
    "print(f\"Completion Tokens: {usage['completion_tokens']}\")\n",
    "print(f\"Total Tokens: {usage['total_tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e10f2-ce25-4eb2-81bf-e41369631a7b",
   "metadata": {},
   "source": [
    "#### Option 2 - Invoke use endpoint name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ae4ef-7630-4623-996e-8ec63a5a4789",
   "metadata": {},
   "source": [
    "**Text as model Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2cb60bf-9e47-4d0f-ae5f-6d188d3e3f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"generated_text\":\"\\n\\nI'm a large language model, created by the Gemma team at Google DeepMind. I can take text and images as inputs and output text. As an open-weights model, I'm widely available for public use!\\n\\nHere are some things I can do:\\n\\n*   **Answer your questions:** I can try my best to provide informative and comprehensive answers.\\n*   **Generate creative content:** I can write stories, poems, code, scripts, musical pieces, email, letters, etc.\\n*   **Translate languages:** I can translate text from one language to another.\\n*   **Summarize text:** I can provide concise summaries of longer texts.\\n*   **Follow your instructions:** I’ll do my best to follow your instructions and complete your requests thoughtfully.\\n\\nHow can I help you today?\"}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "input_text = \"Hi, what can you help me with?\"\n",
    "input_data = {\"inputs\": input_text}\n",
    "encoded_body = json.dumps(input_data).encode('utf-8')\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpointName,\n",
    "    Body=encoded_body,\n",
    "    ContentType='application/json'\n",
    ")\n",
    "\n",
    "print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0bb13-5d64-413a-b585-bb80b3166f12",
   "metadata": {},
   "source": [
    "**Multimodality - Image as input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c5e0374-e2a3-4e16-899f-a10c44229b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"chat.completion\",\"id\":\"\",\"created\":1744011147,\"model\":\"google/gemma-3-4b-it\",\"system_fingerprint\":\"3.2.0-native\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Okay, let's take a look! \\n\\nThe animal on the candy is a **turtle**. You can see the shell pattern clearly printed on the candy. \\n\\nDo you want to know anything more about these candies?\"},\"logprobs\":null,\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":284,\"completion_tokens\":47,\"total_tokens\":331}}\n"
     ]
    }
   ],
   "source": [
    "imagetext_input = payload\n",
    "imagetext_encoded_body = json.dumps(imagetext_input).encode('utf-8')\n",
    "\n",
    "response2 = client.invoke_endpoint(\n",
    "    EndpointName=endpointName,\n",
    "    Body=imagetext_encoded_body,\n",
    "    ContentType='application/json'\n",
    ")\n",
    "\n",
    "print(response2['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3cb0a-2681-4f93-9252-3324791ae342",
   "metadata": {},
   "source": [
    "### (Clean Up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def4f76",
   "metadata": {},
   "source": [
    "After you've finished experimenting with the model, it's important to clean up the resources to avoid ongoing charges. The following steps will guide you through deleting the endpoint, endpoint configuration, and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb3ad98-23f3-4797-a3b5-b1035b727a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_tgi_predictor.delete_model()\n",
    "pretrained_tgi_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83faa6-0f30-4312-aaa5-6e4cf962df07",
   "metadata": {},
   "source": [
    "**Or**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2a19dfd-d9da-4fc4-8a4b-3f8bc7a70565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ca8b1157-041a-42c1-8b70-a1449455fc0c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'ca8b1157-041a-42c1-8b70-a1449455fc0c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 07 Apr 2025 07:34:21 GMT',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "\n",
    "client.delete_model(ModelName=model_name)\n",
    "client.delete_endpoint_config(EndpointConfigName=endpointName)\n",
    "client.delete_endpoint(EndpointName=endpointName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8936b-145a-409d-aa08-50760189df9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
